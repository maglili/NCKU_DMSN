{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AprioriAll"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicate(array)->list:\n",
    "    \"\"\"\n",
    "    remove duplicate element in list maintaining order.\n",
    "    \n",
    "    input: array(list)\n",
    "    \n",
    "    return: new_array (list)\n",
    "    \"\"\"\n",
    "    new_array = []\n",
    "    for i in array:\n",
    "        if i not in new_array:\n",
    "            new_array.append(i)\n",
    "    return new_array          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_data(file):\n",
    "    \"\"\"\n",
    "    Preprocessing data.\n",
    "    \n",
    "    open file as dataframe\n",
    "    \"\"\"\n",
    "    db = {'items':[]}\n",
    "    cid = []\n",
    "    with open(file, encoding='utf-8') as fh:\n",
    "        for row in fh:\n",
    "            row = row.split()\n",
    "            cid.append(row[0])\n",
    "            row.remove(row[0])\n",
    "\n",
    "            db_sequence = [] # sequence of a cunstomer\n",
    "            subsequence = {} # subsequence of a sequence\n",
    "            for idx in range(len(row)-1):\n",
    "                if idx % 2 != 0:\n",
    "                    continue\n",
    "                buy_time = row[idx]\n",
    "                item  = row[idx + 1]\n",
    "                if buy_time not in subsequence:\n",
    "                    subsequence[buy_time] = [item]\n",
    "                else:\n",
    "                    subsequence[buy_time].append(item)\n",
    "\n",
    "            for subseq in subsequence.values():\n",
    "                db_sequence.append(subseq)\n",
    "\n",
    "            db_sequence = remove_duplicate(db_sequence)\n",
    "\n",
    "            db['items'].append(db_sequence)\n",
    "    df = pd.DataFrame(data=db,index=cid)\n",
    "    df.index.name = 'cid'\n",
    "    print('original data:')\n",
    "    print(df)\n",
    "    print('='*20)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_database2(df):\n",
    "    # calc support for each element===========================================\n",
    "    itemset = {}\n",
    "    for idx in range(len(df)):\n",
    "        sequence = df.iloc[idx]['items']\n",
    "        for element in sequence:\n",
    "            if len(element) == 1:\n",
    "                key = str(element)\n",
    "                itemset[key] = itemset.get(key,0)+1\n",
    "            else:\n",
    "                for n in range(len(element)):\n",
    "                    for comb_ in itertools.combinations(element, n+1):\n",
    "                        comb_ = list(comb_)\n",
    "                        comb_ = ','.join(comb_)\n",
    "                        key = str(comb_)\n",
    "                        itemset[key] = itemset.get(key,0)+1\n",
    "                        \n",
    "    # after remove element less than minimal support=======================\n",
    "    clean_itemset = {}\n",
    "    for element,times in itemset.items():\n",
    "        if times > min_support:\n",
    "            clean_itemset[element] = times\n",
    "\n",
    "    # mapping===============================================================\n",
    "    element_list = []\n",
    "    for element in clean_itemset.keys():\n",
    "        element_list.append(element)\n",
    "    element_list.sort()\n",
    "\n",
    "    mapping = {}\n",
    "    for idx,element in enumerate(element_list):\n",
    "        mapping[element] = str(idx)\n",
    "\n",
    "    # inverse mapping ======================================================\n",
    "    inverse_mapping = {}\n",
    "    for key, value in mapping.items():\n",
    "        inverse_mapping[value] = key\n",
    "        \n",
    "\n",
    "    # crete new database====================================================\n",
    "    db2={'items':[]}\n",
    "    cid = []\n",
    "\n",
    "    for idx in range(len(df)):\n",
    "        sequence = df.iloc[idx]['items']\n",
    "        db2_sequence = []\n",
    "        for element in sequence:\n",
    "            subsequence = []\n",
    "            for n in range(len(element)):\n",
    "                for comb_ in itertools.combinations(element, n+1):\n",
    "                    comb_ = list(comb_)\n",
    "                    comb_ = ','.join(comb_)\n",
    "                    if comb_ in mapping:\n",
    "                        subsequence.append(mapping[comb_])\n",
    "            if subsequence != []:\n",
    "                db2_sequence.append(subsequence)       \n",
    "        if db2_sequence != []:\n",
    "            db2_sequence = remove_duplicate(db2_sequence)\n",
    "            db2['items'].append(db2_sequence)\n",
    "            cid.append(idx)\n",
    "    df2 = pd.DataFrame(db2,index=cid)\n",
    "    df2.index.name = 'cid'\n",
    "    print('Processing data:')\n",
    "    print(df2)\n",
    "    print('='*20)\n",
    "    return df2, clean_itemset, mapping, inverse_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequential_pattern(df2, n)->dict:\n",
    "    \"\"\"\n",
    "    find sequential pattern in database.\n",
    "    \n",
    "    df2: DataFrame\n",
    "    n: integer\n",
    "    \n",
    "    return: dict\n",
    "    \n",
    "    warning: if support is too small, this process may cause very long time.\n",
    "    \"\"\"\n",
    "    # calc support\n",
    "    itemset = {}\n",
    "    for idx in range(len(df2)):\n",
    "        sequence = df2.iloc[idx]['items']\n",
    "        combine = []\n",
    "        for element in sequence:\n",
    "            combine.extend(element)\n",
    "        combine = remove_duplicate(combine)\n",
    "        comb_list = []\n",
    "        for comb_ in itertools.combinations(combine, n):\n",
    "            comb_ = list(comb_)\n",
    "            if (len(set(comb_)) == 1) or (comb_ in comb_list):\n",
    "                continue\n",
    "            comb_list.append(comb_)\n",
    "            comb_ = ','.join(comb_)\n",
    "            #print(comb_)            \n",
    "            itemset[comb_] = itemset.get(comb_,0)+1\n",
    "\n",
    "    # find sequential pattern\n",
    "    clean_itemset = {}\n",
    "    for element,times in itemset.items():\n",
    "        if times > min_support:\n",
    "            clean_itemset[element] = times\n",
    "            \n",
    "    return clean_itemset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapping(clean_itemset:dict, inverse_mapping:dict,n):\n",
    "    frequent_sequent = []\n",
    "    for key in clean_itemset.keys():\n",
    "        element_list=[]\n",
    "        element = key.split(',')\n",
    "        #print(element)\n",
    "        for item in element:\n",
    "            #print(inverse_mapping[item])\n",
    "            element_list.append(inverse_mapping[item])\n",
    "        element_list = '|'.join(element_list)\n",
    "        #print(element_list)\n",
    "        frequent_sequent.append(element_list)\n",
    "    print('\\n{}-large Sequence:\\n\\n{}'.format(n,frequent_sequent))\n",
    "    print('len of {}-large Sequence: {}'.format(n, len(frequent_sequent)))\n",
    "    return frequent_sequent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_redundant_pattern(all_frequent_sequent):\n",
    "    remove_list = []\n",
    "    for i in range(len(all_frequent_sequent)):\n",
    "        for j in range(i+1,len(all_frequent_sequent)):\n",
    "            if all_frequent_sequent[i] in all_frequent_sequent[j]:\n",
    "                remove_list.append(all_frequent_sequent[i])\n",
    "    #print(remove_list)\n",
    "    remove_list = list(set(remove_list))\n",
    "    for element in remove_list:\n",
    "        all_frequent_sequent.remove(element)\n",
    "    return all_frequent_sequent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original data:\n",
      "                                                   items\n",
      "cid                                                     \n",
      "1      [[166, 4103, 8715], [4103, 8715], [166, 3704, ...\n",
      "2                     [[2404, 5954, 6282], [2404, 3203]]\n",
      "3      [[5132, 9446], [316, 5132, 6889, 7594], [5132,...\n",
      "4      [[7182, 8985], [3710, 4652, 5069, 8985], [5069...\n",
      "5      [[649, 1264, 2181, 6268], [2181, 5127, 5447, 5...\n",
      "...                                                  ...\n",
      "19996               [[3638, 5868], [1767], [1767, 6415]]\n",
      "19997                                           [[8480]]\n",
      "19998  [[3268, 6149, 6624], [3268, 6149, 6624, 9933],...\n",
      "19999                         [[26, 9706], [8007, 9706]]\n",
      "20000           [[7357], [2046, 5756, 7357, 7467, 9749]]\n",
      "\n",
      "[20000 rows x 1 columns]\n",
      "====================\n",
      "Input minimal support(% of data):1\n",
      "min_support: 200.0\n",
      "====================\n",
      "Processing data:\n",
      "                  items\n",
      "cid                    \n",
      "0      [[31, 64], [88]]\n",
      "2                [[49]]\n",
      "3      [[48], [38, 48]]\n",
      "4        [[52, 54, 53]]\n",
      "5      [[63, 78], [78]]\n",
      "...                 ...\n",
      "19990            [[36]]\n",
      "19991            [[86]]\n",
      "19992            [[90]]\n",
      "19996            [[78]]\n",
      "19997            [[89]]\n",
      "\n",
      "[8312 rows x 1 columns]\n",
      "====================\n",
      "\n",
      "2-large Sequence:\n",
      "\n",
      "['7088|9126', '7088|7088,9126', '9126|7088,9126']\n",
      "len of 2-large Sequence: 3\n",
      "\n",
      "3-large Sequence:\n",
      "\n",
      "['7088|9126|7088,9126']\n",
      "len of 3-large Sequence: 1\n",
      "====================\n",
      "\n",
      "Sequential pattern:\n",
      " ['7088|7088,9126', '7088|9126|7088,9126']\n",
      "len of Sequential pattern: 2\n"
     ]
    }
   ],
   "source": [
    "df = prep_data('./seqdata.dat.txt')\n",
    "min_support = float(input('Input minimal support(% of data):')) * len(df) * 0.01\n",
    "print('min_support:',min_support)\n",
    "print('='*20)\n",
    "df2, _, _, inverse_mapping = create_database2(df)\n",
    "\n",
    "n=2\n",
    "all_frequent_sequent = []\n",
    "while True:\n",
    "    clean_itemset = sequential_pattern(df2,n)\n",
    "    if len(clean_itemset) == 0:\n",
    "        break\n",
    "    frequent_sequent = mapping(clean_itemset, inverse_mapping,n)\n",
    "    all_frequent_sequent.extend(frequent_sequent)\n",
    "    n += 1\n",
    "    if len(clean_itemset) == 1:\n",
    "        break\n",
    "\n",
    "print('='*20)\n",
    "all_frequent_sequent = remove_redundant_pattern(all_frequent_sequent)\n",
    "print('\\nSequential pattern:\\n',all_frequent_sequent)\n",
    "print('len of Sequential pattern:',len(all_frequent_sequent))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
